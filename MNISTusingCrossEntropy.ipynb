{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Input Pipeline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Made suitable for input\n",
    "nClass = 10\n",
    "nH = [256, 64]\n",
    "nY = [10]\n",
    "x_train_flat = x_train.reshape(x_train.shape[0],-1).T\n",
    "x_test_flat = x_test.reshape(x_test.shape[0],-1).T\n",
    "y_train_onehot = np.eye(nClass)[y_train].T\n",
    "y_test_onehot = np.eye(nClass)[y_test].T\n",
    "layers = nH + nY\n",
    "limit = 0.0001\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 60000)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[256, 64, 10]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"#Define\"\n",
    "# Dataset must be of shape - [no of features, no of examples]\n",
    "nY = nClass\n",
    "nH = [50]     #neurons\n",
    "nX = x_train_flat.shape[0]\n",
    "m_train = x_train_flat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 60000)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deepfuzzy:\n",
    "    W = []\n",
    "    b = []\n",
    "    parameters = dict()\n",
    "    act = []\n",
    "    def __init__(self, layers, test_data, train_data, y_train_onehot, y_test_onehot, no_of_examples, iterations):\n",
    "        self.layers = layers\n",
    "        self.test_data = test_data\n",
    "        self.train_data = train_data[:][:no_of_examples]\n",
    "        self.y_train_onehot = y_train_onehot\n",
    "        self.y_test_onehot = y_test_onehot\n",
    "        self.iter = iterations\n",
    "        initialize(self, 'random')\n",
    "    def train(self):\n",
    "        for i in range(self.iter):\n",
    "            forwardProp(self)\n",
    "            compCost(self)\n",
    "            backProp(self)\n",
    "           # if(i%10 == 0):\n",
    "            #    self.saveWeights()\n",
    "    def saveWeights(self):\n",
    "        np.save('W.npy',  self.parameters['W'])  \n",
    "        np.save('b.npy', self.parameters['b'])\n",
    "        my_dict_back = np.load('my_dict.npy')\n",
    "        \n",
    "    def loadWeights(self):\n",
    "        self.W = np.load('W.npy')\n",
    "        self.b = np.load('b.npy')\n",
    "    \n",
    "    def backProp(loss, opt):\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(self, initializer = 'random'):\n",
    "        #parameters = dict()\n",
    "        W = []\n",
    "        b = []\n",
    "        np.random.seed(1)\n",
    "        for i in range(len(self.layers)-1):\n",
    "            W.append(np.random.randn(self.layers[i+1],self.layers[i])*0.01)\n",
    "            b.append(np.random.randn(self.layers[i+1],1)*0.01)\n",
    "        self.parameters['W'] = W\n",
    "        self.parameters['b'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProp(self):\n",
    "    self.act=[]\n",
    "    self.act.append(self.train_data)\n",
    "    for i in range(len(self.layers)-2):\n",
    "        z = np.dot(self.parameters['W'][i], self.act[-1])\n",
    "        self.act.append(sigma(z + self.parameters['b'][i]))  #sigmoid\n",
    "    self.act.append(softmax(np.dot(self.parameters['W'][len(self.layers)-2], self.act[-1])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compCost(self):\n",
    "    cost = -1.0/y_train_onehot.shape[1]*np.sum(np.dot(self.y_train_onehot,np.log(self.act[-1].T))+np.dot((1-self.y_train_onehot),np.log(1-self.act[-1]).T))\n",
    "    print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backProp(self):\n",
    "    dAL = -np.divide(self.y_train_onehot, self.act[-1])+np.divide(1-self.y_train_onehot, 1-self.act[-1])\n",
    "    \n",
    "    dA_prev = dAL\n",
    "    m = y_train_onehot.shape[1]\n",
    "    for i in reversed(range(len(self.layers)-1)):\n",
    "        dA = dA_prev \n",
    "        dZ = linear_activation_backward(dA,self.act[i+1],\"sigmoid\")\n",
    "        dW = 1.0/m*np.dot(dZ, self.act[i].T)\n",
    "\n",
    "        db = 1.0/m*np.sum(dZ,axis=1,keepdims=True)\n",
    "        #print(db)\n",
    "        dA_prev = np.dot(self.parameters['W'][i].T, dZ)\n",
    "        self.parameters['W'][i] = self.parameters['W'][i] - learning_rate*dW\n",
    "        self.parameters['b'][i] = self.parameters['b'][i] - learning_rate*db\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA,cache,activation):\n",
    "    if(activation==\"sigmoid\"):\n",
    "        act =  cache \n",
    "        return dA*act*(1-act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = deepfuzzy([784]+layers,x_test_flat, x_train_flat, y_train_onehot,y_test_onehot, 60000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.515872123871176\n",
      "32.51597104545968\n",
      "32.51606948634523\n",
      "32.516167416812756\n",
      "32.51626480886748\n",
      "32.51636163616691\n",
      "32.51645787395513\n",
      "32.51655349899947\n",
      "32.516648489529345\n",
      "32.51674282517728\n",
      "32.51683648692194\n"
     ]
    }
   ],
   "source": [
    "test.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46169222, 0.4614836 , 0.46165243, ..., 0.46122511, 0.46149073,\n",
       "        0.46119847],\n",
       "       [0.46892141, 0.46921175, 0.46955194, ..., 0.46899174, 0.46976669,\n",
       "        0.46869119],\n",
       "       [0.47187014, 0.47184143, 0.47216815, ..., 0.47169907, 0.47212822,\n",
       "        0.471608  ],\n",
       "       ...,\n",
       "       [0.46566315, 0.46578097, 0.46545652, ..., 0.46590741, 0.46531446,\n",
       "        0.46543962],\n",
       "       [0.47230168, 0.47283099, 0.47257155, ..., 0.47310496, 0.47289695,\n",
       "        0.47267666],\n",
       "       [0.48018227, 0.4802974 , 0.48071575, ..., 0.48039708, 0.48070743,\n",
       "        0.48088176]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.act[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.y_train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
