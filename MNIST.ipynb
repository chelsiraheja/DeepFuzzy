{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Input Pipeline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Made suitable for input\n",
    "nClass = 10\n",
    "nH = [50]\n",
    "nY = [10]\n",
    "x_train_flat = x_train.reshape(x_train.shape[0],-1).T\n",
    "x_test_flat = x_test.reshape(x_test.shape[0],-1).T\n",
    "y_train_onehot = np.eye(nClass)[y_train].T\n",
    "y_test_onehot = np.eye(nClass)[y_test].T\n",
    "layers = nH + nY\n",
    "limit = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 60000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape\n",
    "y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"#Define\"\n",
    "# Dataset must be of shape - [no of features, no of examples]\n",
    "nY = nClass\n",
    "nH = [50]     #neurons\n",
    "nX = x_train_flat.shape[0]\n",
    "m_train = x_train_flat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 60000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 784)\n"
     ]
    }
   ],
   "source": [
    "# Weight must be of shape - WL -> [n[l] , n[l-1]]\n",
    "# Bias must be of shape - BL -> [n[l] , 1]\n",
    "W1 = np.random.randn(nH[0], nX)\n",
    "print(W1.shape)\n",
    "b1 = np.random.randn(nH[0],1)\n",
    "Z1 = np.dot(W1, x_train_flat) + b1\n",
    "labels_mat = np.random.randn(x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deepfuzzy:\n",
    "    W = []\n",
    "    b = []\n",
    "    parameters = dict()\n",
    "    act = []\n",
    "    def __init__(self, layers, test_data, train_data, y_train_onehot):\n",
    "        self.layers = layers\n",
    "        self.test_data = test_data\n",
    "        self.train_data = train_data\n",
    "        self.y_train_onehot = y_train_onehot\n",
    "        initialize(self, 'random')\n",
    "    def train(self):\n",
    "        for i in range(10):\n",
    "            forwardProp(self)\n",
    "            evalError(self)\n",
    "            error(self)\n",
    "    def saveWeights(iterGap):\n",
    "        pass\n",
    "    def loadWeights():\n",
    "        pass\n",
    "    \n",
    "    def backProp(loss, opt):\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(self, initializer = 'random'):\n",
    "        #parameters = dict()\n",
    "        W = []\n",
    "        b = []\n",
    "        for i in range(len(self.layers)-1):\n",
    "            W.append(np.random.randn(self.layers[i+1],self.layers[i]))\n",
    "            b.append(np.random.randn(self.layers[i+1],1))\n",
    "        self.parameters['W'] = W\n",
    "        self.parameters['b'] = b\n",
    "        #return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProp(self):\n",
    "    self.act.append(self.train_data)\n",
    "    for i in range(len(self.layers)-1):\n",
    "        lt = np.dot(self.parameters['W'][i], self.act[-1])\n",
    "        self.act.append(sigma( lt + self.parameters['b'][i]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalError(self):\n",
    "    #err = -(y_train_onehot - eval[-1])(eval[-1])(1-eval[-1])   #####\n",
    "    err1 = np.multiply(np.array(self.y_train_onehot - self.act[-1]), np.array(self.act[-1]))\n",
    "    err = np.multiply(err1, np.array(1-self.act[-1]))\n",
    "    backprop = []\n",
    "    backprop.append(err) # 10,50\n",
    "    self.parameters['W'][-1] += limit*np.dot(self.act[-2],err.T).T\n",
    "    self.parameters['b'][-1] += limit*np.dot(np.ones((1, 60000)),err.T).T\n",
    "    for i in range(len(layers)-2):\n",
    "        err1 = np.multiply(np.array(self.act[-1*i-2]), 1-np.array(self.act[-1*i-2]))\n",
    "        err = np.multiply(err1 , np.array(np.dot(self.parameters['W'][-1*i-1],backprop[-1*i-1])))\n",
    "        backprop.append(err)\n",
    "        self.parameters['W'][-1*i-2] += limit*np.dot(self.act[-1*i-2],err.T)\n",
    "        self.parameters['b'][-1*i-2] += limit*np.dot(np.ones(self.layers[-1*i-2],1),err.T)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = deepfuzzy([5,4,3,1],[[-0.31178367 , 0.72900392,  0.21782079, -0.8990918 ],\n",
    "#  [-2.48678065,  0.91325152 , 1.12706373, -1.51409323],\n",
    "#  [ 1.63929108 ,-0.4298936   ,2.63128056  ,0.60182225],\n",
    "#  [-0.33588161  ,1.23773784  ,0.11112817  ,0.12915125],\n",
    "#  [ 0.07612761 ,-0.15512816  ,0.63422534 , 0.810655  ]],[[-0.31178367 , 0.72900392,  0.21782079, -0.8990918 ],\n",
    "#  [-2.48678065,  0.91325152 , 1.12706373, -1.51409323],\n",
    "#  [ 1.63929108 ,-0.4298936   ,2.63128056  ,0.60182225],\n",
    "#  [-0.33588161  ,1.23773784  ,0.11112817  ,0.12915125],\n",
    "#  [ 0.07612761 ,-0.15512816  ,0.63422534 , 0.810655  ]])b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(self):\n",
    "    err=0.0\n",
    "    for i in range(self.y_train_onehot.shape[0]):\n",
    "        for j in range(self.y_train_onehot.shape[1]):\n",
    "            err = err+ (self.y_train_onehot[i][j] - self.act[-1][i][j])*(self.y_train_onehot[i][j] - self.act[-1][i][j])\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = deepfuzzy([784]+layers,x_test_flat, x_train_flat, y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59912.8605584172\n",
      "59842.523435771334\n",
      "59619.84089522806\n",
      "58811.58284567766\n",
      "59910.74471488517\n",
      "59999.37469965078\n",
      "59999.37227342245\n",
      "59999.369827102106\n",
      "59999.36736044052\n",
      "59999.36487318333\n"
     ]
    }
   ],
   "source": [
    "test.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
