{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Input Pipeline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Made suitable for input\n",
    "nClass = 10\n",
    "nH = [50]\n",
    "nY = [10]\n",
    "x_train_flat = x_train.reshape(x_train.shape[0],-1).T\n",
    "x_test_flat = x_test.reshape(x_test.shape[0],-1).T\n",
    "y_train_onehot = np.eye(nClass)[y_train].T\n",
    "y_test_onehot = np.eye(nClass)[y_test].T\n",
    "layers = nH + nY\n",
    "limit = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 60000)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape\n",
    "y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"#Define\"\n",
    "# Dataset must be of shape - [no of features, no of examples]\n",
    "nY = nClass\n",
    "nH = [50]     #neurons\n",
    "nX = x_train_flat.shape[0]\n",
    "m_train = x_train_flat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 60000)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 784)\n"
     ]
    }
   ],
   "source": [
    "# Weight must be of shape - WL -> [n[l] , n[l-1]]\n",
    "# Bias must be of shape - BL -> [n[l] , 1]\n",
    "W1 = np.random.randn(nH[0], nX)\n",
    "print(W1.shape)\n",
    "b1 = np.random.randn(nH[0],1)\n",
    "Z1 = np.dot(W1, x_train_flat) + b1\n",
    "labels_mat = np.random.randn(x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deepfuzzy:\n",
    "    W = []\n",
    "    b = []\n",
    "    parameters = dict()\n",
    "    act = []\n",
    "    def __init__(self, layers, test_data, train_data, y_train_onehot, y_test_onehot, no_of_examples, iterations):\n",
    "        self.layers = layers\n",
    "        self.test_data = test_data\n",
    "        self.train_data = train_data[:][:no_of_examples]\n",
    "        self.y_train_onehot = y_train_onehot\n",
    "        self.y_test_onehot = y_test_onehot\n",
    "        self.iter = iterations\n",
    "        initialize(self, 'random')\n",
    "    def train(self):\n",
    "        for i in range(iterations):\n",
    "            forwardProp(self)\n",
    "            evalError(self)\n",
    "            error(self)\n",
    "            if(i%10 == 0):\n",
    "                saveWeights(self)\n",
    "    def saveWeights(self):\n",
    "        np.save('W.npy',  self.parameters['W'])  \n",
    "        np.save('b.npy', self.parameters['b'])\n",
    "        my_dict_back = np.load('my_dict.npy')\n",
    "        \n",
    "    def loadWeights(self):\n",
    "        self.W = np.load('W.npy')\n",
    "        self.b = np.load('b.npy')\n",
    "    \n",
    "    def backProp(loss, opt):\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(self, initializer = 'random'):\n",
    "        #parameters = dict()\n",
    "        W = []\n",
    "        b = []\n",
    "        np.random.seed(1)\n",
    "        for i in range(len(self.layers)-1):\n",
    "            W.append(np.random.randn(self.layers[i+1],self.layers[i])*0.01)\n",
    "            b.append(np.random.randn(self.layers[i+1],1)*0.01)\n",
    "        self.parameters['W'] = W\n",
    "        self.parameters['b'] = b\n",
    "        #return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProp(self):\n",
    "    self.act=[]\n",
    "    self.act.append(self.train_data)\n",
    "    for i in range(len(self.layers)-1):\n",
    "        lt = np.dot(self.parameters['W'][i], self.act[-1])\n",
    "        self.act.append(sigma( lt + self.parameters['b'][i]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalError(self):\n",
    "    #err = -(y_train_onehot - eval[-1])(eval[-1])(1-eval[-1])   #####\n",
    "    print(self.act[-1][:][0:6])\n",
    "    print(self.y_train_onehot[:][0:10])\n",
    "    print( \" \")\n",
    "    err1 = np.multiply(np.array(self.y_train_onehot - self.act[-1]), np.array(self.act[-1]))\n",
    "    err = np.multiply(err1, np.array(1-self.act[-1]))\n",
    "    backprop = []\n",
    "    backprop.append(err) # 10,50\n",
    "    self.parameters['W'][-1] += limit*np.dot(self.act[-2],err.T).T\n",
    "    self.parameters['b'][-1] += limit*np.dot(np.ones((1, 60000)),err.T).T\n",
    "    for i in range(len(layers)-2):\n",
    "        err1 = np.multiply(np.array(self.act[-1*i-2]), 1-np.array(self.act[-1*i-2]))\n",
    "        err = np.multiply(err1 , np.array(np.dot(self.parameters['W'][-1*i-1],backprop[-1*i-1])))\n",
    "        backprop.append(err)\n",
    "        self.parameters['W'][-1*i-2] += limit*np.dot(self.act[-1*i-2],err.T).T\n",
    "        self.parameters['b'][-1*i-2] += limit*np.dot(np.ones(1,self.layers[-1*i-2]),err.T).T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(self):\n",
    "    err=0.0\n",
    "    for i in range(self.y_train_onehot.shape[0]):\n",
    "        for j in range(self.y_train_onehot.shape[1]):\n",
    "            err = err+ (self.y_train_onehot[i][j] - self.act[-1][i][j])*(self.y_train_onehot[i][j] - self.act[-1][i][j])\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = deepfuzzy([784]+layers,x_test_flat, x_train_flat, y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48598733 0.48564309 0.48578214 ... 0.48537555 0.48570774 0.48543334]\n",
      " [0.49291132 0.49307808 0.49337561 ... 0.49283897 0.4936824  0.49261958]\n",
      " [0.49686646 0.49670529 0.49699459 ... 0.49655017 0.49704715 0.49654359]\n",
      " [0.49633211 0.49606615 0.4966379  ... 0.4965063  0.49609954 0.49666463]\n",
      " [0.49745922 0.49755527 0.49710699 ... 0.49748092 0.49736458 0.49722498]\n",
      " [0.50301236 0.50350878 0.50285236 ... 0.50260942 0.50321712 0.50269251]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "147992.0911712893\n",
      "[[0.00034702 0.00036183 0.00036306 ... 0.00036133 0.00035357 0.00035126]\n",
      " [0.00039745 0.00041449 0.00041682 ... 0.0004145  0.0004064  0.00040275]\n",
      " [0.00029063 0.00030339 0.00030503 ... 0.00030328 0.00029681 0.00029467]\n",
      " [0.00030746 0.00032072 0.00032282 ... 0.00032142 0.00031339 0.00031248]\n",
      " [0.00027321 0.00028563 0.00028644 ... 0.00028574 0.00027889 0.00027714]\n",
      " [0.00021582 0.0002263  0.00022662 ... 0.00022563 0.0002206  0.00021889]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "59963.1895688562\n",
      "[[0.00034798 0.00036282 0.00036406 ... 0.00036233 0.00035455 0.00035223]\n",
      " [0.00039896 0.00041605 0.00041838 ... 0.00041605 0.00040793 0.00040427]\n",
      " [0.0002913  0.00030408 0.00030573 ... 0.00030398 0.0002975  0.00029535]\n",
      " [0.00030825 0.00032154 0.00032364 ... 0.00032225 0.00031419 0.00031328]\n",
      " [0.00027382 0.00028627 0.00028708 ... 0.00028638 0.00027951 0.00027776]\n",
      " [0.00021617 0.00022666 0.00022698 ... 0.000226   0.00022096 0.00021925]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "59963.092640278825\n",
      "[[0.00034895 0.00036383 0.00036507 ... 0.00036333 0.00035553 0.00035321]\n",
      " [0.00040047 0.00041762 0.00041996 ... 0.00041762 0.00040947 0.0004058 ]\n",
      " [0.00029198 0.00030478 0.00030643 ... 0.00030468 0.00029818 0.00029603]\n",
      " [0.00030905 0.00032237 0.00032448 ... 0.00032308 0.00031501 0.00031409]\n",
      " [0.00027443 0.00028691 0.00028772 ... 0.00028702 0.00028014 0.00027838]\n",
      " [0.00021652 0.00022703 0.00022735 ... 0.00022636 0.00022132 0.0002196 ]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "59962.99517476778\n",
      "[[0.00034992 0.00036484 0.00036608 ... 0.00036433 0.00035652 0.00035419]\n",
      " [0.00040199 0.0004192  0.00042155 ... 0.0004192  0.00041103 0.00040734]\n",
      " [0.00029265 0.00030549 0.00030714 ... 0.00030538 0.00029887 0.00029671]\n",
      " [0.00030985 0.0003232  0.00032532 ... 0.00032391 0.00031582 0.00031491]\n",
      " [0.00027505 0.00028755 0.00028836 ... 0.00028766 0.00028077 0.000279  ]\n",
      " [0.00021688 0.0002274  0.00022772 ... 0.00022673 0.00022168 0.00021996]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "59962.897167635034\n",
      "[[0.0003509  0.00036585 0.0003671  ... 0.00036535 0.00035752 0.00035518]\n",
      " [0.00040353 0.00042079 0.00042315 ... 0.00042079 0.00041259 0.00040889]\n",
      " [0.00029333 0.00030619 0.00030785 ... 0.00030608 0.00029956 0.0002974 ]\n",
      " [0.00031066 0.00032404 0.00032616 ... 0.00032475 0.00031664 0.00031573]\n",
      " [0.00027567 0.00028819 0.00028901 ... 0.0002883  0.0002814  0.00027963]\n",
      " [0.00021723 0.00022777 0.00022809 ... 0.0002271  0.00022204 0.00022032]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "59962.79861412741\n",
      "[[0.00035188 0.00036687 0.00036812 ... 0.00036637 0.00035852 0.00035617]\n",
      " [0.00040507 0.00042239 0.00042476 ... 0.0004224  0.00041417 0.00041045]\n",
      " [0.00029402 0.0003069  0.00030856 ... 0.00030679 0.00030026 0.00029809]\n",
      " [0.00031147 0.00032488 0.00032701 ... 0.00032559 0.00031747 0.00031655]\n",
      " [0.00027629 0.00028884 0.00028966 ... 0.00028895 0.00028203 0.00028026]\n",
      " [0.00021759 0.00022814 0.00022846 ... 0.00022747 0.0002224  0.00022068]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "59962.69950944023\n",
      "[[0.00035287 0.0003679  0.00036915 ... 0.00036739 0.00035952 0.00035717]\n",
      " [0.00040663 0.00042401 0.00042638 ... 0.00042402 0.00041576 0.00041203]\n",
      " [0.0002947  0.00030761 0.00030927 ... 0.0003075  0.00030096 0.00029879]\n",
      " [0.00031229 0.00032573 0.00032786 ... 0.00032644 0.0003183  0.00031738]\n",
      " [0.00027692 0.00028949 0.00029031 ... 0.0002896  0.00028267 0.00028089]\n",
      " [0.00021794 0.00022851 0.00022883 ... 0.00022784 0.00022277 0.00022104]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "59962.59984870625\n",
      "[[0.00035387 0.00036893 0.00037018 ... 0.00036842 0.00036053 0.00035818]\n",
      " [0.0004082  0.00042564 0.00042802 ... 0.00042564 0.00041736 0.00041362]\n",
      " [0.00029539 0.00030833 0.00030999 ... 0.00030822 0.00030166 0.00029948]\n",
      " [0.00031311 0.00032658 0.00032871 ... 0.00032729 0.00031913 0.00031821]\n",
      " [0.00027754 0.00029014 0.00029096 ... 0.00029025 0.00028331 0.00028153]\n",
      " [0.0002183  0.00022888 0.00022921 ... 0.00022821 0.00022313 0.0002214 ]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "59962.49962699877\n",
      "[[0.00035487 0.00036997 0.00037122 ... 0.00036946 0.00036155 0.00035919]\n",
      " [0.00040979 0.00042728 0.00042967 ... 0.00042729 0.00041898 0.00041522]\n",
      " [0.00029608 0.00030905 0.00031071 ... 0.00030894 0.00030237 0.00030018]\n",
      " [0.00031393 0.00032744 0.00032957 ... 0.00032815 0.00031997 0.00031905]\n",
      " [0.00027818 0.0002908  0.00029162 ... 0.00029091 0.00028395 0.00028217]\n",
      " [0.00021866 0.00022926 0.00022958 ... 0.00022859 0.0002235  0.00022177]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      " \n",
      "59962.39883932962\n"
     ]
    }
   ],
   "source": [
    "test.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
